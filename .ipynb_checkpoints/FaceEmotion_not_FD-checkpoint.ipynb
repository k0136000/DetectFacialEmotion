{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c24177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file list: ['happy', 'sad', 'surprise', 'neutral', 'angry']\n",
      "Loaded the images of dataset-happy\n",
      "\n",
      "happy:10970\n",
      "Loaded the images of dataset-sad\n",
      "\n",
      "sad:7408\n",
      "Loaded the images of dataset-surprise\n",
      "\n",
      "surprise:7422\n",
      "Loaded the images of dataset-neutral\n",
      "\n",
      "neutral:9930\n",
      "Loaded the images of dataset-angry\n",
      "\n",
      "angry:6045\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 98\u001b[0m\n\u001b[1;32m     68\u001b[0m     labeled \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# img_data = np.array(img_data_list)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# labels = np.array(labels)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# 2: 0010000\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#하나의 이미지에 대해 0과 1로 라벨링된(원핫인코딩된)배열을 리턴받음.\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m Y \u001b[38;5;241m=\u001b[39m np_utils\u001b[38;5;241m.\u001b[39mto_categorical(labels, \u001b[43mnum_classes\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#matplotlib을 통해 보여줄 그래프의 크기를 직접 지정해 준것.\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "import os\n",
    "data_path = './Input/emotions'\n",
    "file_list = os.listdir(data_path)\n",
    "file_list.remove('.DS_Store')\n",
    "\n",
    "print(\"file list:\",file_list)\n",
    "\n",
    "# Any results you write to the current directory are saved as output\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "#디렉토리에서 이미지를 추출하기\n",
    "\n",
    "num_epoch=10\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "labels = []\n",
    "labeled = 0\n",
    "img_count = 0\n",
    "#우리가 파일을 만든 순서가 아닌 컴퓨터가 지가 읽는 순서대로 파일을 불러옴.\n",
    "for dataset in file_list:\n",
    "    img_one_cat_len = 0\n",
    "    one_cat_list = []\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        #이미지를 해당 경로에서 하나씩 읽어와서 (48,48)사이즈로 읽어와 img_data_list라는 array에 저장.        \n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(224,224),interpolation=cv2.INTER_LINEAR)\n",
    "#         input_img_gray = cv2.cvtColor(input_img_resize, cv2.COLOR_RGB2GRAY)\n",
    "        img_data_list.append(input_img_resize)\n",
    "        one_cat_list.append(input_img_resize)\n",
    "\n",
    "        img_one_cat_len +=1\n",
    "    print(f'{dataset}:{len(one_cat_list)}')\n",
    "    #라벨링 넘파이 배열 생성 \n",
    "    for label in range(img_one_cat_len):\n",
    "        labels.append(labeled)\n",
    "\n",
    "    labeled += 1\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "labels = np.array(labels)\n",
    "\n",
    "#이미지 데이터 정규화\n",
    "\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255 #normalization\n",
    "print(img_data.shape)\n",
    "\n",
    "num_classes = len(file_list)\n",
    "\n",
    "# 카테고리 리스트로 선언\n",
    "names = file_list\n",
    "\n",
    "#라벨 이름 리턴\n",
    "def getLabel(labels): \n",
    "    return names[labels.index(1)]\n",
    "def getLabel_Incoding(preds):\n",
    "    index = np.argmax(preds)\n",
    "    return names[index-1]    \n",
    "\n",
    "# 훈련, 검증 데이터 셋 분리.\n",
    "\n",
    "#원핫 인코딩 /  (파라미터 값, 0으로된 배열의 크기)\n",
    "# 0: 1000000\n",
    "# 1: 0100000\n",
    "# 2: 0010000\n",
    "#하나의 이미지에 대해 0과 1로 라벨링된(원핫인코딩된)배열을 리턴받음.\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "#모델 생성 및 요약\n",
    "# import creat_model as cm\n",
    "\n",
    "from create_model import create_model_224\n",
    "\n",
    "model_custom = create_model_224()\n",
    "\n",
    "model_custom.summary()\n",
    "\n",
    "#Conduct k-Fold Cross-validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# kfold 교차 검증\n",
    "# 데이터가 적은 데이터 셋에 대하여 정확도를 향상 시키기 위함.\n",
    "# 이는 기존에 Training / Validation / Test 세개의 집단으로 분류하는것 보다 Training / Test로만 분류할때 학습 데이터 셋이 더 많기 때문.\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 K Fold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "#Data Augmentation 기능 / 데이터 증강 기법\n",
    "#모델의 성능을 높이면서 오버피팅을 극복하기 위해 학습 데이터의 다양성을 늘리기 위함.\n",
    "#하나의 원본 이미지를 다양항 버전으로 만들어 학습시키는 것.\n",
    "#대표적인 데이터 증강 기법으로는 원본 이미지를 수평 또는 수직 반전 시키는 방법, 회전시키는 방법, 일부를 자르는 방법,RGB채널 순서를 바꾸거나 \n",
    "#픽셀값을 변경하여 원본 이미지의 색조를 변경시키는 것들이 있음.\n",
    "#이러한 이미지 증강 기법을 tf.keras의 ImageDataGenerator 가 대신해줌.\n",
    "#이 툴 이외에 Data Albumenation이나, ImgAug, Tensorflow Image Library 등 다양한 데이터 증강 기법 툴들이 있음.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 증강법 1단계.ImageDataGenerator 객체(aug)를 생성하면서 증강을 수행할 유형들을 지정.\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "#Training Model \n",
    "BS = 8 # batch size\n",
    "EPOCHS = 100 # epochs\n",
    "\n",
    "result = []\n",
    "scores_loss = []\n",
    "scores_val_loss = []\n",
    "scores_acc = []\n",
    "scores_val_acc=[]\n",
    "k_no = 0\n",
    "\n",
    "#Kfold 객체의 split()을 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "#split()이 알아서 학습용 검증용 데이터를 나누어줌. 위에서 k=5라고 지정한 경우 for문이 5번 돌아 가면서 학습용, 검증용 데이터를 나누어 줌.\n",
    "for train_index, test_index in kf.split(x):\n",
    "    #Kfold 객채의 split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터를 추출함.\n",
    "    X_Train,X_Test = x[train_index], x[test_index]\n",
    "    Y_Train,Y_Test = y[train_index], y[test_index]\n",
    "\n",
    "    # 최적의 모델을 저장할 경로\n",
    "    file_path = \"./weights_best_emotion_detect6.h5\"\n",
    "    # 콜백 함수. (체크포인트, 조기 종료 선언)\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='loss', save_best_only=True, mode='min')\n",
    "    early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=8)\n",
    "\n",
    "    callbacks_list = [checkpoint, early]\n",
    "\n",
    "    #이미지 증강법 2단계 aug.flow(X,y,batch_size=,shuffle=) : X(훈련 이미지),y(라벨), 이미지를 한번에 몇개 업로드 시킬지에 대한 배치 사이즈,데이터 셔플 유무\n",
    "    #flow 메소드로 생성한 객체는 Numpy Array Iterator 객체로 우리가 흔히 아는 Python Iterator처럼 loop문이나 next()함수를 사용해 Iterator 안에 데이터를 하나씩 호출 가능.\n",
    "\n",
    "    hist = model_custom.fit_generator(aug.flow(X_Train, Y_Train), epochs=EPOCHS,validation_data=(X_Test, Y_Test), callbacks=callbacks_list)\n",
    "    # model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, validation_data=(X_Test, Y_Test), verbose=1)\n",
    "    \n",
    "    result.append(model_custom.predict(X_Test))\n",
    "    scores_loss.append(hist.history['loss'])\n",
    "    scores_val_loss.append(hist.history['val_loss'])\n",
    "    scores_acc.append(hist.history['accuracy'])\n",
    "    scores_val_acc.append(hist.history['val_accuracy'])\n",
    "    k_no+=1\n",
    "\n",
    "print(scores_loss)    \n",
    "print(scores_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba01d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
